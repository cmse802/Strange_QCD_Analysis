{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Using Optimization in High Energy Physics</center>\n",
    "\n",
    "<center>by Nick Juliano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "High energy physics (HEP) seeks to explain phenomena not currently treated by our accepted model for particle physics, the Standard Model. A common task in HEP is using data from cutting edge experiments to fit predictive models. Gradually, this analysis allows us to understand the underlying physics when we don't have a complete theory to describe it.\n",
    "\n",
    "The fitting process alone can be a lengty and detailed project, as straightforward regression often does not lead to a suitable fit. Within the past decade, high energy physicists have turned to deep learning algorithms to fit their models. At the heart of these algorithms is an optimization problem: given a model g($\\beta$), which depends on fit parameters $\\beta$, we wish to $\\textit{minimize}$ an associated cost function $C$ that assesses how well the model describes the input data. We adjust the paramters $\\beta_i$ to minimize $C$. Though it occasionally might be possible to solve for the parameters using analytic linear algebra techniques, in general we need a numerical method to minimize $C$.\n",
    "\n",
    "As an example, consider the cost function for a simple binary classification problem (see Ref. 1),\n",
    "$$\n",
    "    C(\\beta) = \\sum_{i=1}^{n} (y_i (\\beta_0 + \\beta_1x_i) - \\log(1 + exp(\\beta_0 + \\beta_1 x_i))) \n",
    "$$\n",
    "\n",
    "where $y$ is a set of dependent variables, in this case our two possible (binary) outcomes, and $x$ is our input data. This function a convex function of $\\beta$, so finding a local minimum is equivalent to finding the global minimum. We can find local minima with respect to each parameter in the usual way, by differentiating and setting the result equal to zero and solving. However, we may also write the optimization step in a more compact way:\n",
    "$$\n",
    "    \\frac{\\partial C}{\\partial \\beta} = - X^T (y-p),\n",
    "$$\n",
    "\n",
    "where $X$ is an $n \\times p$ matrix containing the $n$ input predictors and the associated fitted probabilities $p$ of each. We are left with a system of equations that, when solved, will yield a vector of parameters $\\beta$ which minimize the cost function and thus represent our most accurate model. The most common technique for solving this system is called the Newton-Raphson method, though I will not include the details here.\n",
    "\n",
    "---\n",
    "\n",
    "The above example uses a classification problem, though we most often encounter regression problems when we apply machine learning methods to HEP. Still, the general procedure of minimizing a cost function is the same for both types of problem. In the work that I have done so far, we have generated our input (or training) data using functional forms that mimic the distributions seen in HEP experiments, with some noise added. We then train a machine learning model and test it on experimental data to evaluate the model's predictive power. However, there is no clear \"correct\" cost function to apply in our case, so we have looked into implementing different types to see which is best suited to our purposes. It may be advantageous to construct a sort of meta-optimization problem (minimizing the error from using each cost function) to decide which function works best.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### References\n",
    "\n",
    "1. Morten Hjorth-Jensen, \"Data Analysis and Machine Learning: Logistic Regression and Gradient Methods\", 2020 Nuclear TALENT Course (lecture notes)\n",
    "\n",
    "2. LÃ©on Bottou, Frank E. Curtis, and Jorge Nocedal, \"Optimization Methods for Large-Scale Machine Learning\", 2018, SIAM Review Vol. 60 Issue 2 (223).\n",
    "Link: https://epubs.siam.org/doi/10.1137/16M1080173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
